{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "<center><h2>ALTeGraD 2023<br>Lab Session 3: Transfer learning for NLP</h2> 24 / 10 / 2023<br> Dr. G. Shang, H. Abdine<br><br>\n",
        "\n",
        "<hr>\n",
        "<b>Ben Kabongo B.</b><br/>\n",
        "MVA, ENS Paris-Saclay\n",
        "<hr>\n",
        "\n",
        "</center>\n",
        "\n",
        "<br><br>\n",
        "In this lab we will:\n",
        "* Implement and pretrain a language model with transformer architecture.\n",
        "* Use the pretrained model (transfer learning) to perform a sentiment analysis task which consists of classifying some books reviews into positive and negative ones.\n",
        "* Compare the performance of the pretrained model to a model trained from scratch.\n",
        " <br>\n",
        "\n",
        "<b>The deadline for this lab is October 31, 2023 11:59 PM.</b> More details about the submission and the architecture for this lab can be found in the handout PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntokens, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(num_embeddings=ntokens, embedding_dim=nhid)\n",
        "        self.pos_encoder = PositionalEncoding(nhid)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=nhid, nhead=nhead, dim_feedforward=nhid, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer=encoder_layers, num_layers=nlayers)\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntokens=ntokens, nhead=nhead, nhid=nhid, nlayers=nlayers, dropout=dropout)\n",
        "        self.classifier = ClassificationHead(nhid=nhid, nclasses=nclasses)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        x = self.base(src, src_mask)\n",
        "        output = self.classifier(x)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rhb2gkUhJMR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b20f820b-1d3e-4d5c-bb76-bd254a5567b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 100])\n"
          ]
        }
      ],
      "source": [
        "ntokens = 100 # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape) # is it the right shape?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5qjd26ghWuff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8703e99a-9b1f-4397-b30f-00d0b2480857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-24 19:46:07--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt.1’\n",
            "\n",
            "dict.txt.1          100%[===================>] 564.05K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-10-24 19:46:07 (22.3 MB/s) - ‘dict.txt.1’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vFdH_-JeFbGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de163c2d-024e-471d-b77e-08cf6f057287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁trop\n"
          ]
        }
      ],
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        token2ind[word] =  idx + 4\n",
        "\n",
        "ind2token = {v:k for k, v in token2ind.items()}\n",
        "\n",
        "print(ind2token[1111])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence = [self.token2ind[\"<sos>\"]] + [\n",
        "            self.token2ind.get(tok, self.token2ind[\"<oov>\"]) for tok in sequence]\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): #step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(device)\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) #step 2\n",
        "        if task == 'classification':\n",
        "            #last vector only\n",
        "            output = output[-1, :, :]\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target =  data[1]\n",
        "        target = target.to(device)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pgf6BDB9jUr6"
      },
      "outputs": [],
      "source": [
        "ntokens = len(token2ind) # the size of vocabulary\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "outputs": [],
      "source": [
        "# optimization paramerters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Bwh3n9xZQy4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b6810a5-d609-4d17-d118-21e456855d71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-24 19:46:10--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt.1’\n",
            "\n",
            "pretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-10-24 19:46:10 (78.7 MB/s) - ‘pretraining_subset.txt.1’ saved [10146460/10146460]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0m11g4ScjZaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a2c5c4-3561-4ad6-c135-a3cddf4db737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 7.32559 | ppl 1518.670\n",
            "| epoch   1 |  1000/ 3125 steps | loss 6.50891 | ppl  671.097\n",
            "| epoch   1 |  1500/ 3125 steps | loss 6.25796 | ppl  522.150\n",
            "| epoch   1 |  2000/ 3125 steps | loss 6.09978 | ppl  445.760\n",
            "| epoch   1 |  2500/ 3125 steps | loss 5.99208 | ppl  400.245\n",
            "| epoch   1 |  3000/ 3125 steps | loss 5.88082 | ppl  358.104\n",
            "| epoch   2 |   500/ 3125 steps | loss 5.60648 | ppl  272.184\n",
            "| epoch   2 |  1000/ 3125 steps | loss 5.56935 | ppl  262.264\n",
            "| epoch   2 |  1500/ 3125 steps | loss 5.52876 | ppl  251.831\n",
            "| epoch   2 |  2000/ 3125 steps | loss 5.51010 | ppl  247.176\n",
            "| epoch   2 |  2500/ 3125 steps | loss 5.47112 | ppl  237.726\n",
            "| epoch   2 |  3000/ 3125 steps | loss 5.45308 | ppl  233.475\n"
          ]
        }
      ],
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\",\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-BcBC6FSkMH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ebbe9b9-9280-427c-c814-7bbda820c11f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-24 19:50:58--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt.1’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M   240MB/s    in 0.4s    \n",
            "\n",
            "2023-10-24 19:51:01 (240 MB/s) - ‘pretrained_model_4layers.pt.1’ saved [88093955/88093955]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt')\n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tBRRVsWqlIoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32d311c3-6c57-4b77-be76-1ab6f3c2bf73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "--2023-10-24 19:51:06--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model.1’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-24 19:51:06 (26.8 MB/s) - ‘sentencepiece.french.model.1’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece   # uncomment this if you are using google colab\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "outputs": [],
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces] # list of tokens\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind =  torch.argmax(torch.softmax(out, dim=2), dim=2)\n",
        "    return int(next_token_ind[-1, 0]), out\n",
        "\n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "    next_tokens = []\n",
        "    for _ in range(max_len):\n",
        "        next_token_ind, _ = infer_next_token(sent)\n",
        "        tok = ind2token[next_token_ind]\n",
        "        if tok == \"<eos>\":\n",
        "            break\n",
        "        next_tokens.append(tok)\n",
        "        sent += \" \" + tok\n",
        "    return next_tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "f83Nn5nSly4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8fea1b8-f1a5-4a75-b3a9-d31f5797a0a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁gens', '▁qui', '▁ont', '▁été', '▁très', '▁accueillants', '▁et', '▁sympathiques', '.']\n"
          ]
        }
      ],
      "source": [
        "sent = \"Bonjour les\"\n",
        "print(infer_next_tokens(sent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0K1BZsblmEmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f58f4f3-e837-4a00-9bef-33f33c534e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-24 19:51:06--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm.1’\n",
            "\n",
            "train.review.spm.1  100%[===================>]   1.43M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-24 19:51:06 (34.7 MB/s) - ‘train.review.spm.1’ saved [1495960/1495960]\n",
            "\n",
            "--2023-10-24 19:51:07--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label.1’\n",
            "\n",
            "train.label.1       100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-24 19:51:07 (49.9 MB/s) - ‘train.label.1’ saved [3200/3200]\n",
            "\n",
            "--2023-10-24 19:51:07--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm.1’\n",
            "\n",
            "test.review.spm.1   100%[===================>]   1.78M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-10-24 19:51:07 (34.6 MB/s) - ‘test.review.spm.1’ saved [1864544/1864544]\n",
            "\n",
            "--2023-10-24 19:51:07--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label.1’\n",
            "\n",
            "test.label.1        100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-24 19:51:07 (69.7 MB/s) - ‘test.label.1’ saved [4000/4000]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "outputs": [],
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader):\n",
        "    model.eval()\n",
        "    acc = 0.0\n",
        "    n_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for idx, data in enumerate(data_loader):\n",
        "            src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(device)\n",
        "            input = data[0].to(device)\n",
        "            output = model(input, src_mask)\n",
        "            output = output[-1, :, :]\n",
        "            output = output.view(-1, output.shape[-1])\n",
        "            target =  data[1]\n",
        "            target = target.to(device)\n",
        "            acc += (torch.argmax(output, dim=1) == target).sum().item()\n",
        "            n_samples += len(target)\n",
        "    return acc/n_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "outputs": [],
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "i-xclMCpnVpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c40616b0-1ddf-48cc-c03a-cace2880523b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.77168 | ppl    2.163\n",
            "| epoch   1 |   100/  200 steps | loss 0.76055 | ppl    2.139\n",
            "| epoch   1 |   150/  200 steps | loss 0.69735 | ppl    2.008\n",
            "Acc : 0.5515\n",
            "| epoch   2 |    50/  200 steps | loss 0.66921 | ppl    1.953\n",
            "| epoch   2 |   100/  200 steps | loss 0.63361 | ppl    1.884\n",
            "| epoch   2 |   150/  200 steps | loss 0.59399 | ppl    1.811\n",
            "Acc : 0.6975\n",
            "| epoch   3 |    50/  200 steps | loss 0.50223 | ppl    1.652\n",
            "| epoch   3 |   100/  200 steps | loss 0.36505 | ppl    1.441\n",
            "| epoch   3 |   150/  200 steps | loss 0.43545 | ppl    1.546\n",
            "Acc : 0.74\n",
            "| epoch   4 |    50/  200 steps | loss 0.25985 | ppl    1.297\n",
            "| epoch   4 |   100/  200 steps | loss 0.18312 | ppl    1.201\n",
            "| epoch   4 |   150/  200 steps | loss 0.19388 | ppl    1.214\n",
            "Acc : 0.7525\n",
            "| epoch   5 |    50/  200 steps | loss 0.11818 | ppl    1.125\n",
            "| epoch   5 |   100/  200 steps | loss 0.10685 | ppl    1.113\n",
            "| epoch   5 |   150/  200 steps | loss 0.13177 | ppl    1.141\n",
            "Acc : 0.6865\n",
            "| epoch   6 |    50/  200 steps | loss 0.06802 | ppl    1.070\n",
            "| epoch   6 |   100/  200 steps | loss 0.05142 | ppl    1.053\n",
            "| epoch   6 |   150/  200 steps | loss 0.06089 | ppl    1.063\n",
            "Acc : 0.7315\n",
            "| epoch   7 |    50/  200 steps | loss 0.00125 | ppl    1.001\n",
            "| epoch   7 |   100/  200 steps | loss 0.00347 | ppl    1.003\n",
            "| epoch   7 |   150/  200 steps | loss 0.02658 | ppl    1.027\n",
            "Acc : 0.7385\n",
            "| epoch   8 |    50/  200 steps | loss 0.00007 | ppl    1.000\n",
            "| epoch   8 |   100/  200 steps | loss 0.04918 | ppl    1.050\n",
            "| epoch   8 |   150/  200 steps | loss 0.01987 | ppl    1.020\n",
            "Acc : 0.7435\n",
            "| epoch   9 |    50/  200 steps | loss 0.00433 | ppl    1.004\n",
            "| epoch   9 |   100/  200 steps | loss 0.00007 | ppl    1.000\n",
            "| epoch   9 |   150/  200 steps | loss 0.00016 | ppl    1.000\n",
            "Acc : 0.75\n",
            "| epoch  10 |    50/  200 steps | loss 0.00116 | ppl    1.001\n",
            "| epoch  10 |   100/  200 steps | loss 0.03236 | ppl    1.033\n",
            "| epoch  10 |   150/  200 steps | loss 0.03410 | ppl    1.035\n",
            "Acc : 0.74\n",
            "| epoch  11 |    50/  200 steps | loss 0.00082 | ppl    1.001\n",
            "| epoch  11 |   100/  200 steps | loss 0.02522 | ppl    1.026\n",
            "| epoch  11 |   150/  200 steps | loss 0.00514 | ppl    1.005\n",
            "Acc : 0.7395\n",
            "| epoch  12 |    50/  200 steps | loss 0.00015 | ppl    1.000\n",
            "| epoch  12 |   100/  200 steps | loss 0.00136 | ppl    1.001\n",
            "| epoch  12 |   150/  200 steps | loss 0.03829 | ppl    1.039\n",
            "Acc : 0.7225\n",
            "| epoch  13 |    50/  200 steps | loss 0.00945 | ppl    1.009\n",
            "| epoch  13 |   100/  200 steps | loss 0.00007 | ppl    1.000\n",
            "| epoch  13 |   150/  200 steps | loss 0.00776 | ppl    1.008\n",
            "Acc : 0.747\n",
            "| epoch  14 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  14 |   100/  200 steps | loss 0.04090 | ppl    1.042\n",
            "| epoch  14 |   150/  200 steps | loss 0.01550 | ppl    1.016\n",
            "Acc : 0.7425\n",
            "| epoch  15 |    50/  200 steps | loss 0.02878 | ppl    1.029\n",
            "| epoch  15 |   100/  200 steps | loss 0.02116 | ppl    1.021\n",
            "| epoch  15 |   150/  200 steps | loss 0.00696 | ppl    1.007\n",
            "Acc : 0.713\n",
            "\n",
            "=====PRETRAINED MODEL======\n",
            "| epoch   1 |    50/  200 steps | loss 0.80103 | ppl    2.228\n",
            "| epoch   1 |   100/  200 steps | loss 0.69088 | ppl    1.995\n",
            "| epoch   1 |   150/  200 steps | loss 0.65444 | ppl    1.924\n",
            "Acc : 0.691\n",
            "| epoch   2 |    50/  200 steps | loss 0.53618 | ppl    1.709\n",
            "| epoch   2 |   100/  200 steps | loss 0.45304 | ppl    1.573\n",
            "| epoch   2 |   150/  200 steps | loss 0.48400 | ppl    1.623\n",
            "Acc : 0.7875\n",
            "| epoch   3 |    50/  200 steps | loss 0.35290 | ppl    1.423\n",
            "| epoch   3 |   100/  200 steps | loss 0.32772 | ppl    1.388\n",
            "| epoch   3 |   150/  200 steps | loss 0.47113 | ppl    1.602\n",
            "Acc : 0.8025\n",
            "| epoch   4 |    50/  200 steps | loss 0.23459 | ppl    1.264\n",
            "| epoch   4 |   100/  200 steps | loss 0.33790 | ppl    1.402\n",
            "| epoch   4 |   150/  200 steps | loss 0.36017 | ppl    1.434\n",
            "Acc : 0.7875\n",
            "| epoch   5 |    50/  200 steps | loss 0.21778 | ppl    1.243\n",
            "| epoch   5 |   100/  200 steps | loss 0.18888 | ppl    1.208\n",
            "| epoch   5 |   150/  200 steps | loss 0.22085 | ppl    1.247\n",
            "Acc : 0.8065\n",
            "| epoch   6 |    50/  200 steps | loss 0.14516 | ppl    1.156\n",
            "| epoch   6 |   100/  200 steps | loss 0.20996 | ppl    1.234\n",
            "| epoch   6 |   150/  200 steps | loss 0.14205 | ppl    1.153\n",
            "Acc : 0.797\n",
            "| epoch   7 |    50/  200 steps | loss 0.08200 | ppl    1.085\n",
            "| epoch   7 |   100/  200 steps | loss 0.13549 | ppl    1.145\n",
            "| epoch   7 |   150/  200 steps | loss 0.09553 | ppl    1.100\n",
            "Acc : 0.7965\n",
            "| epoch   8 |    50/  200 steps | loss 0.10813 | ppl    1.114\n",
            "| epoch   8 |   100/  200 steps | loss 0.05430 | ppl    1.056\n",
            "| epoch   8 |   150/  200 steps | loss 0.04273 | ppl    1.044\n",
            "Acc : 0.791\n",
            "| epoch   9 |    50/  200 steps | loss 0.01109 | ppl    1.011\n",
            "| epoch   9 |   100/  200 steps | loss 0.03811 | ppl    1.039\n",
            "| epoch   9 |   150/  200 steps | loss 0.08968 | ppl    1.094\n",
            "Acc : 0.7975\n",
            "| epoch  10 |    50/  200 steps | loss 0.02947 | ppl    1.030\n",
            "| epoch  10 |   100/  200 steps | loss 0.04958 | ppl    1.051\n",
            "| epoch  10 |   150/  200 steps | loss 0.00644 | ppl    1.006\n",
            "Acc : 0.791\n",
            "| epoch  11 |    50/  200 steps | loss 0.06666 | ppl    1.069\n",
            "| epoch  11 |   100/  200 steps | loss 0.02941 | ppl    1.030\n",
            "| epoch  11 |   150/  200 steps | loss 0.04502 | ppl    1.046\n",
            "Acc : 0.7965\n",
            "| epoch  12 |    50/  200 steps | loss 0.01418 | ppl    1.014\n",
            "| epoch  12 |   100/  200 steps | loss 0.02745 | ppl    1.028\n",
            "| epoch  12 |   150/  200 steps | loss 0.07856 | ppl    1.082\n",
            "Acc : 0.7865\n",
            "| epoch  13 |    50/  200 steps | loss 0.03263 | ppl    1.033\n",
            "| epoch  13 |   100/  200 steps | loss 0.04125 | ppl    1.042\n",
            "| epoch  13 |   150/  200 steps | loss 0.04488 | ppl    1.046\n",
            "Acc : 0.8\n",
            "| epoch  14 |    50/  200 steps | loss 0.02395 | ppl    1.024\n",
            "| epoch  14 |   100/  200 steps | loss 0.07276 | ppl    1.075\n",
            "| epoch  14 |   150/  200 steps | loss 0.03105 | ppl    1.032\n",
            "Acc : 0.798\n",
            "| epoch  15 |    50/  200 steps | loss 0.01200 | ppl    1.012\n",
            "| epoch  15 |   100/  200 steps | loss 0.00135 | ppl    1.001\n",
            "| epoch  15 |   150/  200 steps | loss 0.00046 | ppl    1.000\n",
            "Acc : 0.799\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        print(\"Acc :\", acc)\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RCpBIdTHojm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "7f5b44de-9fa4-41ce-da73-199793874e0b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Visualize the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "plt.plot(from_scratch_valid_acc, label=\"from scratch\")\n",
        "plt.plot(pretrained_valid_acc, label=\"pretrained\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6.15 ('altegrad')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "1f3cfdeab8dd8f9900bd16266619de191cf0f5e09365d74b1fba1714dce58066"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}