{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "<center><h2>ALTeGraD 2023<br>Lab Session 3: Transfer learning for NLP</h2> 24 / 10 / 2023<br> Dr. G. Shang, H. Abdine<br><br>\n",
        "\n",
        "<hr>\n",
        "<b>Ben Kabongo B.</b><br/>\n",
        "MVA, ENS Paris-Saclay\n",
        "<hr>\n",
        "\n",
        "</center>\n",
        "\n",
        "<br><br>\n",
        "In this lab we will:\n",
        "* Implement and pretrain a language model with transformer architecture.\n",
        "* Use the pretrained model (transfer learning) to perform a sentiment analysis task which consists of classifying some books reviews into positive and negative ones.\n",
        "* Compare the performance of the pretrained model to a model trained from scratch.\n",
        " <br>\n",
        "\n",
        "<b>The deadline for this lab is October 31, 2023 11:59 PM.</b> More details about the submission and the architecture for this lab can be found in the handout PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntokens, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(num_embeddings=ntokens, embedding_dim=nhid)\n",
        "        self.pos_encoder = PositionalEncoding(nhid)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=nhid, nhead=nhead, dim_feedforward=nhid, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer=encoder_layers, num_layers=nlayers)\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntokens=ntokens, nhead=nhead, nhid=nhid, nlayers=nlayers, dropout=dropout)\n",
        "        self.classifier = ClassificationHead(nhid=nhid, nclasses=nclasses)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        x = self.base(src, src_mask)\n",
        "        output = self.classifier(x)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhb2gkUhJMR0",
        "outputId": "092411b0-dbcd-4cab-8199-e8e6d5f28b3e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 6, 100])\n"
          ]
        }
      ],
      "source": [
        "ntokens = 100 # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape) # is it the right shape?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qjd26ghWuff",
        "outputId": "72dcb405-2070-4910-8cf4-cd82653c6dc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-24 18:31:17--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt’\n",
            "\n",
            "dict.txt            100%[===================>] 564.05K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-10-24 18:31:17 (18.0 MB/s) - ‘dict.txt’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFdH_-JeFbGA",
        "outputId": "86d35b45-3fc2-4bda-c77a-de4503f8ab28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▁trop\n"
          ]
        }
      ],
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        token2ind[word] =  idx + 4\n",
        "\n",
        "ind2token = {v:k for k, v in token2ind.items()}\n",
        "\n",
        "print(ind2token[1111])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence = [self.token2ind[\"<sos>\"]] + [\n",
        "            self.token2ind.get(tok, self.token2ind[\"<oov>\"]) for tok in sequence]\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=max_len,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): #step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(device)\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) #step 2\n",
        "        if task == 'classification':\n",
        "            #last vector only\n",
        "            output = output[-1, :, :]\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target =  data[1]\n",
        "        target = target.to(device)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pgf6BDB9jUr6"
      },
      "outputs": [],
      "source": [
        "ntokens = len(token2ind) # the size of vocabulary\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "outputs": [],
      "source": [
        "# optimization paramerters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwh3n9xZQy4e",
        "outputId": "f9378a46-4a85-48f6-d673-bf212a4ef834"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-24 18:32:06--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt’\n",
            "\n",
            "pretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-10-24 18:32:06 (151 MB/s) - ‘pretraining_subset.txt’ saved [10146460/10146460]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m11g4ScjZaR",
        "outputId": "68a429c8-e5b3-468e-c428-eb3a83fd41c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 7.34613 | ppl 1550.181\n",
            "| epoch   1 |  1000/ 3125 steps | loss 6.54457 | ppl  695.460\n",
            "| epoch   1 |  1500/ 3125 steps | loss 6.25569 | ppl  520.968\n",
            "| epoch   1 |  2000/ 3125 steps | loss 6.08383 | ppl  438.707\n",
            "| epoch   1 |  2500/ 3125 steps | loss 5.96365 | ppl  389.026\n",
            "| epoch   1 |  3000/ 3125 steps | loss 5.90083 | ppl  365.340\n",
            "| epoch   2 |   500/ 3125 steps | loss 5.61190 | ppl  273.664\n",
            "| epoch   2 |  1000/ 3125 steps | loss 5.54317 | ppl  255.488\n",
            "| epoch   2 |  1500/ 3125 steps | loss 5.52931 | ppl  251.969\n",
            "| epoch   2 |  2000/ 3125 steps | loss 5.51795 | ppl  249.124\n",
            "| epoch   2 |  2500/ 3125 steps | loss 5.47068 | ppl  237.621\n",
            "| epoch   2 |  3000/ 3125 steps | loss 5.45382 | ppl  233.649\n"
          ]
        }
      ],
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\",\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BcBC6FSkMH3",
        "outputId": "25b04a4c-27b2-4880-a331-ef053ead081c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-24 18:37:26--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M   269MB/s    in 0.3s    \n",
            "\n",
            "2023-10-24 18:37:26 (269 MB/s) - ‘pretrained_model_4layers.pt’ saved [88093955/88093955]\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt')\n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBRRVsWqlIoQ",
        "outputId": "6093cf16-c8df-4355-a33c-549cc15843fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "--2023-10-24 18:37:42--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-24 18:37:42 (25.4 MB/s) - ‘sentencepiece.french.model’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece   # uncomment this if you are using google colab\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "outputs": [],
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces] # list of tokens\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind =  torch.argmax(torch.softmax(out, dim=2), dim=2)\n",
        "    return int(next_token_ind[-1, 0]), out\n",
        "\n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "    next_tokens = []\n",
        "    for _ in range(max_len):\n",
        "        next_token_ind, _ = infer_next_token(sent)\n",
        "        tok = ind2token[next_token_ind]\n",
        "        if tok == \"<eos>\":\n",
        "            break\n",
        "        next_tokens.append(tok)\n",
        "        sent += \" \" + tok\n",
        "    return next_tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f83Nn5nSly4v",
        "outputId": "d19db85b-92aa-420d-a149-dcba3c7461a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['▁gens', '▁qui', '▁ont', '▁été', '▁très', '▁accueillants', '▁et', '▁sympathiques', '.']\n"
          ]
        }
      ],
      "source": [
        "sent = \"Bonjour les\"\n",
        "print(infer_next_tokens(sent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K1BZsblmEmx",
        "outputId": "347699ce-b76f-49cf-81a8-50879496d867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-24 18:56:32--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm’\n",
            "\n",
            "train.review.spm    100%[===================>]   1.43M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-24 18:56:32 (40.7 MB/s) - ‘train.review.spm’ saved [1495960/1495960]\n",
            "\n",
            "--2023-10-24 18:56:32--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label’\n",
            "\n",
            "train.label         100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-24 18:56:33 (57.5 MB/s) - ‘train.label’ saved [3200/3200]\n",
            "\n",
            "--2023-10-24 18:56:33--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm’\n",
            "\n",
            "test.review.spm     100%[===================>]   1.78M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-24 18:56:33 (47.1 MB/s) - ‘test.review.spm’ saved [1864544/1864544]\n",
            "\n",
            "--2023-10-24 18:56:33--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label’\n",
            "\n",
            "test.label          100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-24 18:56:34 (48.8 MB/s) - ‘test.label’ saved [4000/4000]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "outputs": [],
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader):\n",
        "    model.eval()\n",
        "    acc = 0.0\n",
        "    n_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for idx, data in enumerate(data_loader):\n",
        "            src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(device)\n",
        "            input = data[0].to(device)\n",
        "            output = model(input, src_mask)\n",
        "            output = output[-1, :, :]\n",
        "            output = output.view(-1, output.shape[-1])\n",
        "            target =  data[1]\n",
        "            target = target.to(device)\n",
        "            acc += (torch.argmax(output, dim=1) == target).sum().item()\n",
        "            n_samples += len(target)\n",
        "    return acc/n_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "outputs": [],
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-xclMCpnVpw",
        "outputId": "b710615b-1bed-42ef-fd61-849593d114ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.78580 | ppl    2.194\n",
            "| epoch   1 |   100/  200 steps | loss 0.71916 | ppl    2.053\n",
            "| epoch   1 |   150/  200 steps | loss 0.72233 | ppl    2.059\n",
            "Acc : 0.5245\n",
            "| epoch   2 |    50/  200 steps | loss 0.64923 | ppl    1.914\n",
            "| epoch   2 |   100/  200 steps | loss 0.61317 | ppl    1.846\n",
            "| epoch   2 |   150/  200 steps | loss 0.59013 | ppl    1.804\n",
            "Acc : 0.6805\n",
            "| epoch   3 |    50/  200 steps | loss 0.42802 | ppl    1.534\n",
            "| epoch   3 |   100/  200 steps | loss 0.35907 | ppl    1.432\n",
            "| epoch   3 |   150/  200 steps | loss 0.41734 | ppl    1.518\n",
            "Acc : 0.743\n",
            "| epoch   4 |    50/  200 steps | loss 0.25329 | ppl    1.288\n",
            "| epoch   4 |   100/  200 steps | loss 0.17583 | ppl    1.192\n",
            "| epoch   4 |   150/  200 steps | loss 0.12011 | ppl    1.128\n",
            "Acc : 0.7475\n",
            "| epoch   5 |    50/  200 steps | loss 0.07367 | ppl    1.076\n",
            "| epoch   5 |   100/  200 steps | loss 0.04129 | ppl    1.042\n",
            "| epoch   5 |   150/  200 steps | loss 0.20064 | ppl    1.222\n",
            "Acc : 0.7525\n",
            "| epoch   6 |    50/  200 steps | loss 0.06369 | ppl    1.066\n",
            "| epoch   6 |   100/  200 steps | loss 0.03079 | ppl    1.031\n",
            "| epoch   6 |   150/  200 steps | loss 0.00940 | ppl    1.009\n",
            "Acc : 0.7515\n",
            "| epoch   7 |    50/  200 steps | loss 0.03842 | ppl    1.039\n",
            "| epoch   7 |   100/  200 steps | loss 0.00917 | ppl    1.009\n",
            "| epoch   7 |   150/  200 steps | loss 0.00688 | ppl    1.007\n",
            "Acc : 0.7595\n",
            "| epoch   8 |    50/  200 steps | loss 0.02087 | ppl    1.021\n",
            "| epoch   8 |   100/  200 steps | loss 0.00508 | ppl    1.005\n",
            "| epoch   8 |   150/  200 steps | loss 0.02520 | ppl    1.026\n",
            "Acc : 0.7405\n",
            "| epoch   9 |    50/  200 steps | loss 0.02947 | ppl    1.030\n",
            "| epoch   9 |   100/  200 steps | loss 0.00499 | ppl    1.005\n",
            "| epoch   9 |   150/  200 steps | loss 0.01556 | ppl    1.016\n",
            "Acc : 0.74\n",
            "| epoch  10 |    50/  200 steps | loss 0.02004 | ppl    1.020\n",
            "| epoch  10 |   100/  200 steps | loss 0.02093 | ppl    1.021\n",
            "| epoch  10 |   150/  200 steps | loss 0.02251 | ppl    1.023\n",
            "Acc : 0.736\n",
            "| epoch  11 |    50/  200 steps | loss 0.03311 | ppl    1.034\n",
            "| epoch  11 |   100/  200 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch  11 |   150/  200 steps | loss 0.01946 | ppl    1.020\n",
            "Acc : 0.7565\n",
            "| epoch  12 |    50/  200 steps | loss 0.01376 | ppl    1.014\n",
            "| epoch  12 |   100/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch  12 |   150/  200 steps | loss 0.00002 | ppl    1.000\n",
            "Acc : 0.7425\n",
            "| epoch  13 |    50/  200 steps | loss 0.01399 | ppl    1.014\n",
            "| epoch  13 |   100/  200 steps | loss 0.01902 | ppl    1.019\n",
            "| epoch  13 |   150/  200 steps | loss 0.02516 | ppl    1.025\n",
            "Acc : 0.751\n",
            "| epoch  14 |    50/  200 steps | loss 0.00649 | ppl    1.007\n",
            "| epoch  14 |   100/  200 steps | loss 0.02680 | ppl    1.027\n",
            "| epoch  14 |   150/  200 steps | loss 0.01171 | ppl    1.012\n",
            "Acc : 0.753\n",
            "| epoch  15 |    50/  200 steps | loss 0.01107 | ppl    1.011\n",
            "| epoch  15 |   100/  200 steps | loss 0.02920 | ppl    1.030\n",
            "| epoch  15 |   150/  200 steps | loss 0.00556 | ppl    1.006\n",
            "Acc : 0.7105\n",
            "\n",
            "=====PRETRAINED MODEL======\n",
            "| epoch   1 |    50/  200 steps | loss 0.88081 | ppl    2.413\n",
            "| epoch   1 |   100/  200 steps | loss 0.69371 | ppl    2.001\n",
            "| epoch   1 |   150/  200 steps | loss 0.63055 | ppl    1.879\n",
            "Acc : 0.697\n",
            "| epoch   2 |    50/  200 steps | loss 0.52028 | ppl    1.682\n",
            "| epoch   2 |   100/  200 steps | loss 0.52946 | ppl    1.698\n",
            "| epoch   2 |   150/  200 steps | loss 0.46521 | ppl    1.592\n",
            "Acc : 0.755\n",
            "| epoch   3 |    50/  200 steps | loss 0.39138 | ppl    1.479\n",
            "| epoch   3 |   100/  200 steps | loss 0.44439 | ppl    1.560\n",
            "| epoch   3 |   150/  200 steps | loss 0.40596 | ppl    1.501\n",
            "Acc : 0.794\n",
            "| epoch   4 |    50/  200 steps | loss 0.33938 | ppl    1.404\n",
            "| epoch   4 |   100/  200 steps | loss 0.32462 | ppl    1.384\n",
            "| epoch   4 |   150/  200 steps | loss 0.29884 | ppl    1.348\n",
            "Acc : 0.798\n",
            "| epoch   5 |    50/  200 steps | loss 0.19843 | ppl    1.219\n",
            "| epoch   5 |   100/  200 steps | loss 0.24091 | ppl    1.272\n",
            "| epoch   5 |   150/  200 steps | loss 0.24803 | ppl    1.281\n",
            "Acc : 0.801\n",
            "| epoch   6 |    50/  200 steps | loss 0.17565 | ppl    1.192\n",
            "| epoch   6 |   100/  200 steps | loss 0.12470 | ppl    1.133\n",
            "| epoch   6 |   150/  200 steps | loss 0.41019 | ppl    1.507\n",
            "Acc : 0.8015\n",
            "| epoch   7 |    50/  200 steps | loss 0.15824 | ppl    1.171\n",
            "| epoch   7 |   100/  200 steps | loss 0.12528 | ppl    1.133\n",
            "| epoch   7 |   150/  200 steps | loss 0.11885 | ppl    1.126\n",
            "Acc : 0.795\n",
            "| epoch   8 |    50/  200 steps | loss 0.09027 | ppl    1.094\n",
            "| epoch   8 |   100/  200 steps | loss 0.07198 | ppl    1.075\n",
            "| epoch   8 |   150/  200 steps | loss 0.07112 | ppl    1.074\n",
            "Acc : 0.799\n",
            "| epoch   9 |    50/  200 steps | loss 0.04072 | ppl    1.042\n",
            "| epoch   9 |   100/  200 steps | loss 0.05515 | ppl    1.057\n",
            "| epoch   9 |   150/  200 steps | loss 0.11446 | ppl    1.121\n",
            "Acc : 0.794\n",
            "| epoch  10 |    50/  200 steps | loss 0.03718 | ppl    1.038\n",
            "| epoch  10 |   100/  200 steps | loss 0.08374 | ppl    1.087\n",
            "| epoch  10 |   150/  200 steps | loss 0.03800 | ppl    1.039\n",
            "Acc : 0.8015\n",
            "| epoch  11 |    50/  200 steps | loss 0.06389 | ppl    1.066\n",
            "| epoch  11 |   100/  200 steps | loss 0.01035 | ppl    1.010\n",
            "| epoch  11 |   150/  200 steps | loss 0.05573 | ppl    1.057\n",
            "Acc : 0.794\n",
            "| epoch  12 |    50/  200 steps | loss 0.06355 | ppl    1.066\n",
            "| epoch  12 |   100/  200 steps | loss 0.02182 | ppl    1.022\n",
            "| epoch  12 |   150/  200 steps | loss 0.02861 | ppl    1.029\n",
            "Acc : 0.7995\n",
            "| epoch  13 |    50/  200 steps | loss 0.01997 | ppl    1.020\n",
            "| epoch  13 |   100/  200 steps | loss 0.02024 | ppl    1.020\n",
            "| epoch  13 |   150/  200 steps | loss 0.01690 | ppl    1.017\n",
            "Acc : 0.8055\n",
            "| epoch  14 |    50/  200 steps | loss 0.00638 | ppl    1.006\n",
            "| epoch  14 |   100/  200 steps | loss 0.00270 | ppl    1.003\n",
            "| epoch  14 |   150/  200 steps | loss 0.07258 | ppl    1.075\n",
            "Acc : 0.8005\n",
            "| epoch  15 |    50/  200 steps | loss 0.04175 | ppl    1.043\n",
            "| epoch  15 |   100/  200 steps | loss 0.06253 | ppl    1.065\n",
            "| epoch  15 |   150/  200 steps | loss 0.02103 | ppl    1.021\n",
            "Acc : 0.798\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        print(\"Acc :\", acc)\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "RCpBIdTHojm6",
        "outputId": "0fd6ebe0-aa96-46e4-accc-cf7c80fbfdeb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Visualize the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "plt.plot(from_scratch_valid_acc, label=\"from scratch\")\n",
        "plt.plot(pretrained_valid_acc, label=\"pretrained\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6.15 ('altegrad')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "1f3cfdeab8dd8f9900bd16266619de191cf0f5e09365d74b1fba1714dce58066"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
